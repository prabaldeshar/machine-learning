{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is a pereceptron?\n",
    "- A perceptron takes several binary inputs, x1, x2, ..., and produces as single input. \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./markdown-images/perceptron.png\">\n",
    "</p>\n",
    "\n",
    "- The above example shows the perceptron has three inputs x1, x2 and x3. \n",
    "- Weights were introduced, w1, w2,..., to express the importance to the respective inputs.\n",
    "- The neurons output, 0 or 1 is determined by whether the weighted sum $\\sum_{j} wjxj$ is less than or greater than the threshold value.\n",
    "- In algebaric terms: <br />\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./markdown-images/perceptron_equation.png\">\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formal defination of an artifical neuron\n",
    "Formally we can put the idea behind artifical neurons into the context of a binary classification task where we refer to our two classes as 1 (postive class) and -1 (negative class) for simplicity.\n",
    "\n",
    "We can define a decision fucnion $\\phi$(z) that takes a linera combination of input values,x, and the corresponding weight vector, **w**, where z is so called net input z = $w_{1}x_{1} + w_{2}x_{2} + \\cdots + w_{n}x_{n}$\n",
    "\n",
    "w = $\\begin{bmatrix} w_{1} \\\\ \\vdots \\\\ w_{m} \\end{bmatrix}$\n",
    "x = $\\begin{bmatrix} x_{1} \\\\ \\vdots \\\\ x_{m} \\end{bmatrix}$\n",
    "\n",
    "If the net input of a particular example $X^(i)$ is greater than the threshold, $\\theta $, we predict class 1, otherwise we predict class -1.  \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./markdown-images/decision_function.png\">\n",
    "</p\n",
    "\n",
    "For simplicity, we can bring the threshold, $\\theta$, to the left side of the equation and define a weight-zero as $w_{0}=-\\theta $ and $x_{0}=1$ so that we write $z$ in a more compact form:\n",
    "\n",
    "$z = w_{0}x_{0} + w_{1}w_{2} + \\cdots + w_{m}x_{m} = w^T x$\n",
    "\n",
    "Here, the negative threshold,or weight, $w_{0} = -\\theta$ is usually called the **bias unit**.\n",
    "\n",
    "The following figure illustrates how the the net input $z = w^T x $ is squashed into a binary output (-1 and 1) by the decision function and how it can be used to distingusih betweeen two **linearly seperable classes**.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./markdown-images/graph_preceptron.png\">\n",
    "</p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The perceptron learning rule\n",
    "The perceptron algorithm can be summarizd by the following steps:\n",
    "\n",
    "1. Initilize the weights to 0 or small random numbers.\n",
    "1. For each training exampel, $X^i$\n",
    "    - Compute the ouput value, \n",
    "    - Update the weight\n",
    "\n",
    "The weight vector can be updated as written below:\n",
    "$w_{j} = w_{j} + \\Delta w_{j}$\n",
    "\n",
    "Update value for weight $w_{j}$\n",
    "\n",
    "$\\Delta w_{j} = \\eta (y^i - \\hat y ^i) x_{j} ^ i $\n",
    "\n",
    "Here, <br/>\n",
    " - $ \\eta $ is the learning rate <br/>\n",
    " - $y^i$ is the *i*th **true class label** for *i*th  training example <br/>\n",
    " - $\\hat y^i$ is the predicted class label  \n",
    "\n",
    "\n",
    "It  is important to note that the convergence of the perceptron is only guaranteed if two classes are linearly separable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron Diagram\n",
    "\n",
    "![preceptron-diagram](./markdown-images/perceptron_diagram.png) \n",
    "\n",
    "The digram shows that the preceptron recives the inputs and combines them with their corresponding weights. The net input is then passed to the threshold function, which generates a binary output of -1 or +1. During the learning phase this output is used to calculate the erros and update the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implentation of preceptron using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb6fa1767a1e71d85bec8c42f873ca19270f8f93bde4e75d65e361f3717e7f94"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
